{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPErytL8yOcX4hVZF+mX125",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiggusMaximus/Tensorflow_Certification_Preparation_Dicoding/blob/main/B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQevGf4YKviO"
      },
      "outputs": [],
      "source": [
        "# ===================================================================================================\n",
        "# PROBLEM B4\n",
        "#\n",
        "# Build and train a classifier for the BBC-text dataset.\n",
        "# This is a multiclass classification problem.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 91%\n",
        "# ===================================================================================================   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import csv as csv\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LZy_-OeCkbdB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_tokenizer(train_sentences, num_words, oov_token):\n",
        "  tokenizer = Tokenizer(num_words = num_words, oov_token = oov_token)\n",
        "  tokenizer.fit_on_texts(train_sentences)\n",
        "  return tokenizer\n",
        "\n",
        "def seq_and_pad(sentences, tokenizer, padding, maxlen, trunc_type):\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "  padded_sequences = pad_sequences(sequences, padding = padding, maxlen = maxlen, truncating = trunc_type)\n",
        "  return padded_sequences\n",
        "\n",
        "def tokenize_labels(all_labels, split_labels):\n",
        "  label_tokenizer = Tokenizer()\n",
        "  label_tokenizer.fit_on_texts(all_labels)\n",
        "  label_seq = np.array(label_tokenizer.texts_to_sequences(split_labels))\n",
        "  label_seq_np = np.array(label_seq) - 1\n",
        "  return label_seq_np"
      ],
      "metadata": {
        "id": "nM4dYHElYUN8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solution_B4():\n",
        "    bbc = pd.read_csv(\n",
        "        'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
        "    bbc.to_csv('bbc-text.csv', index = False)\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "    \n",
        "    with open(\"bbc-text.csv\", 'r') as csvfile:\n",
        "      reader = csv.reader(csvfile, delimiter=',')\n",
        "      next(reader)\n",
        "      for row in reader:\n",
        "        labels.append(row[0])\n",
        "        sentence = row[1]\n",
        "        for word in stopwords:\n",
        "          token = \" \" + word + \" \"\n",
        "          sentence = sentence.replace(token, \" \")\n",
        "        sentences.append(sentence)\n",
        "    \n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or you can not pass this test\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_portion = .8\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    # Using \"shuffle=False\"\n",
        "    train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
        "        sentences, \n",
        "        labels, \n",
        "        train_size=training_portion, \n",
        "        shuffle=False\n",
        "    )\n",
        "    # Fit your tokenizer with training data\n",
        "    tokenizer =  Tokenizer(\n",
        "        num_words=vocab_size, \n",
        "        oov_token=oov_tok\n",
        "    )\n",
        "\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "    train_padded_seq = seq_and_pad(train_sentences, tokenizer, padding_type, max_length, trunc_type)\n",
        "    val_padded_seq = seq_and_pad(test_sentences, tokenizer, padding_type, max_length, trunc_type)\n",
        "\n",
        "    train_label_seq = tokenize_labels(labels, train_labels)\n",
        "    val_label_seq = tokenize_labels(labels, test_labels)\n",
        "\n",
        "    model = tf.keras.Sequential([ \n",
        "        tf.keras.layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim, \n",
        "            input_length=max_length),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dense(6, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy']) \n",
        "    model.fit(\n",
        "        train_padded_seq, \n",
        "        train_label_seq, \n",
        "        epochs=300, \n",
        "        validation_data=(val_padded_seq, val_label_seq)\n",
        "    )    \n",
        "\n",
        "    # Make sure you are using \"sparse_categorical_crossentropy\" as a loss fuction\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "S3zdN6Pokbm6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "  # DO NOT CHANGE THIS CODE\n",
        "  model = solution_B4()\n",
        "  model.save(\"model_B4.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq4fSAdxkXUx",
        "outputId": "4bbf2d97-9bd1-4cbd-8664-e0a52e77e8c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "56/56 [==============================] - 1s 5ms/step - loss: 1.7590 - accuracy: 0.2247 - val_loss: 1.7200 - val_accuracy: 0.2270\n",
            "Epoch 2/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.6792 - accuracy: 0.2410 - val_loss: 1.6283 - val_accuracy: 0.2787\n",
            "Epoch 3/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.5592 - accuracy: 0.3815 - val_loss: 1.4844 - val_accuracy: 0.4472\n",
            "Epoch 4/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.5180 - val_loss: 1.2976 - val_accuracy: 0.5438\n",
            "Epoch 5/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1712 - accuracy: 0.5983 - val_loss: 1.0936 - val_accuracy: 0.6180\n",
            "Epoch 6/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.9778 - accuracy: 0.6747 - val_loss: 0.9418 - val_accuracy: 0.6742\n",
            "Epoch 7/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.7163 - val_loss: 0.8202 - val_accuracy: 0.7348\n",
            "Epoch 8/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.8006 - val_loss: 0.7209 - val_accuracy: 0.7910\n",
            "Epoch 9/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.8713 - val_loss: 0.6312 - val_accuracy: 0.8697\n",
            "Epoch 10/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.9124 - val_loss: 0.5543 - val_accuracy: 0.8921\n",
            "Epoch 11/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.9348 - val_loss: 0.4844 - val_accuracy: 0.9236\n",
            "Epoch 12/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.9478 - val_loss: 0.4319 - val_accuracy: 0.9191\n",
            "Epoch 13/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.9556 - val_loss: 0.3899 - val_accuracy: 0.9213\n",
            "Epoch 14/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9612 - val_loss: 0.3576 - val_accuracy: 0.9213\n",
            "Epoch 15/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9669 - val_loss: 0.3371 - val_accuracy: 0.9303\n",
            "Epoch 16/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9719 - val_loss: 0.3049 - val_accuracy: 0.9258\n",
            "Epoch 17/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9736 - val_loss: 0.2944 - val_accuracy: 0.9303\n",
            "Epoch 18/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9775 - val_loss: 0.2805 - val_accuracy: 0.9348\n",
            "Epoch 19/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9826 - val_loss: 0.2721 - val_accuracy: 0.9348\n",
            "Epoch 20/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9860 - val_loss: 0.2624 - val_accuracy: 0.9326\n",
            "Epoch 21/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9910 - val_loss: 0.2580 - val_accuracy: 0.9371\n",
            "Epoch 22/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9933 - val_loss: 0.2530 - val_accuracy: 0.9416\n",
            "Epoch 23/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9944 - val_loss: 0.2472 - val_accuracy: 0.9393\n",
            "Epoch 24/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9955 - val_loss: 0.2413 - val_accuracy: 0.9348\n",
            "Epoch 25/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9949 - val_loss: 0.2382 - val_accuracy: 0.9371\n",
            "Epoch 26/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9983 - val_loss: 0.2414 - val_accuracy: 0.9371\n",
            "Epoch 27/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9978 - val_loss: 0.2396 - val_accuracy: 0.9393\n",
            "Epoch 28/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9989 - val_loss: 0.2373 - val_accuracy: 0.9393\n",
            "Epoch 29/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9994 - val_loss: 0.2394 - val_accuracy: 0.9416\n",
            "Epoch 30/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9371\n",
            "Epoch 31/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9416\n",
            "Epoch 32/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9393\n",
            "Epoch 33/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9393\n",
            "Epoch 34/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9393\n",
            "Epoch 35/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9416\n",
            "Epoch 36/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9416\n",
            "Epoch 37/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9393\n",
            "Epoch 38/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9416\n",
            "Epoch 39/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9393\n",
            "Epoch 40/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9393\n",
            "Epoch 41/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9393\n",
            "Epoch 42/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9393\n",
            "Epoch 43/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9438\n",
            "Epoch 44/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9371\n",
            "Epoch 45/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9371\n",
            "Epoch 46/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9416\n",
            "Epoch 47/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9393\n",
            "Epoch 48/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9393\n",
            "Epoch 49/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9393\n",
            "Epoch 50/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9393\n",
            "Epoch 51/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9371\n",
            "Epoch 52/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9393\n",
            "Epoch 53/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9348\n",
            "Epoch 54/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9348\n",
            "Epoch 55/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9371\n",
            "Epoch 56/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9348\n",
            "Epoch 57/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9348\n",
            "Epoch 58/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9348\n",
            "Epoch 59/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9348\n",
            "Epoch 60/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9326\n",
            "Epoch 61/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9348\n",
            "Epoch 62/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9348\n",
            "Epoch 63/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9348\n",
            "Epoch 64/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9348\n",
            "Epoch 65/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9371\n",
            "Epoch 66/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9348\n",
            "Epoch 67/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9326\n",
            "Epoch 68/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9348\n",
            "Epoch 69/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9348\n",
            "Epoch 70/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9348\n",
            "Epoch 71/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9348\n",
            "Epoch 72/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9348\n",
            "Epoch 73/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9348\n",
            "Epoch 74/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9348\n",
            "Epoch 75/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9348\n",
            "Epoch 76/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9348\n",
            "Epoch 77/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9348\n",
            "Epoch 78/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9348\n",
            "Epoch 79/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9348\n",
            "Epoch 80/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9348\n",
            "Epoch 81/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9348\n",
            "Epoch 82/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9348\n",
            "Epoch 83/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9348\n",
            "Epoch 84/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9348\n",
            "Epoch 85/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9348\n",
            "Epoch 86/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9348\n",
            "Epoch 87/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9348\n",
            "Epoch 88/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9348\n",
            "Epoch 89/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9348\n",
            "Epoch 90/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 9.7331e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9348\n",
            "Epoch 91/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 9.2907e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9348\n",
            "Epoch 92/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.8865e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9348\n",
            "Epoch 93/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 8.5263e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9348\n",
            "Epoch 94/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.1663e-04 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9348\n",
            "Epoch 95/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.8167e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9348\n",
            "Epoch 96/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.4991e-04 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9326\n",
            "Epoch 97/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.1898e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9348\n",
            "Epoch 98/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 6.8878e-04 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9348\n",
            "Epoch 99/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.6203e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9348\n",
            "Epoch 100/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.3554e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9348\n",
            "Epoch 101/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.0855e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9326\n",
            "Epoch 102/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 5.8476e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9326\n",
            "Epoch 103/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.6199e-04 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9326\n",
            "Epoch 104/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 5.3824e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9326\n",
            "Epoch 105/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.1657e-04 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9326\n",
            "Epoch 106/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.9645e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9326\n",
            "Epoch 107/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.7680e-04 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9326\n",
            "Epoch 108/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.5989e-04 - accuracy: 1.0000 - val_loss: 0.3153 - val_accuracy: 0.9326\n",
            "Epoch 109/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.4203e-04 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9326\n",
            "Epoch 110/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.2442e-04 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9326\n",
            "Epoch 111/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.0755e-04 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9326\n",
            "Epoch 112/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 3.9129e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9326\n",
            "Epoch 113/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.7690e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9326\n",
            "Epoch 114/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.6166e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9326\n",
            "Epoch 115/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.4790e-04 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9326\n",
            "Epoch 116/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.3633e-04 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9326\n",
            "Epoch 117/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 3.2378e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9326\n",
            "Epoch 118/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.1076e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9326\n",
            "Epoch 119/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 2.9836e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9326\n",
            "Epoch 120/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.8705e-04 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9326\n",
            "Epoch 121/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.7654e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9326\n",
            "Epoch 122/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6651e-04 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9326\n",
            "Epoch 123/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 2.5667e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9326\n",
            "Epoch 124/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4685e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9326\n",
            "Epoch 125/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3841e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9326\n",
            "Epoch 126/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2926e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9326\n",
            "Epoch 127/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2076e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9326\n",
            "Epoch 128/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1399e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9326\n",
            "Epoch 129/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0512e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9326\n",
            "Epoch 130/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9767e-04 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9326\n",
            "Epoch 131/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9018e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9326\n",
            "Epoch 132/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.8375e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9326\n",
            "Epoch 133/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7690e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9326\n",
            "Epoch 134/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.7088e-04 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9326\n",
            "Epoch 135/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6435e-04 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9326\n",
            "Epoch 136/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5839e-04 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9326\n",
            "Epoch 137/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.5323e-04 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9326\n",
            "Epoch 138/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.4768e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9326\n",
            "Epoch 139/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4216e-04 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9326\n",
            "Epoch 140/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3718e-04 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9326\n",
            "Epoch 141/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3219e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9326\n",
            "Epoch 142/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2770e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9326\n",
            "Epoch 143/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2305e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9326\n",
            "Epoch 144/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.1874e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9326\n",
            "Epoch 145/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 1.1457e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9326\n",
            "Epoch 146/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1063e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9326\n",
            "Epoch 147/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0674e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9326\n",
            "Epoch 148/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0322e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9326\n",
            "Epoch 149/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.9329e-05 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9326\n",
            "Epoch 150/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.5917e-05 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9326\n",
            "Epoch 151/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.2704e-05 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9326\n",
            "Epoch 152/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.9416e-05 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9326\n",
            "Epoch 153/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.6374e-05 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9326\n",
            "Epoch 154/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.3454e-05 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9326\n",
            "Epoch 155/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.0477e-05 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9326\n",
            "Epoch 156/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.7818e-05 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9326\n",
            "Epoch 157/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.5065e-05 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9326\n",
            "Epoch 158/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.2447e-05 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9326\n",
            "Epoch 159/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.0155e-05 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.9326\n",
            "Epoch 160/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.7799e-05 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9326\n",
            "Epoch 161/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.5244e-05 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9326\n",
            "Epoch 162/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.3111e-05 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9326\n",
            "Epoch 163/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.0942e-05 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9326\n",
            "Epoch 164/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.8949e-05 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9326\n",
            "Epoch 165/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.6855e-05 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9326\n",
            "Epoch 166/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.5108e-05 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9326\n",
            "Epoch 167/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.3185e-05 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9326\n",
            "Epoch 168/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.1268e-05 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9326\n",
            "Epoch 169/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.9597e-05 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9326\n",
            "Epoch 170/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.7876e-05 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9326\n",
            "Epoch 171/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.6329e-05 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9326\n",
            "Epoch 172/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.4798e-05 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9326\n",
            "Epoch 173/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.3255e-05 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9326\n",
            "Epoch 174/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.1789e-05 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9326\n",
            "Epoch 175/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.0509e-05 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9326\n",
            "Epoch 176/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.9075e-05 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9326\n",
            "Epoch 177/300\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 3.7763e-05 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9326\n",
            "Epoch 178/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.6580e-05 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9326\n",
            "Epoch 179/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.5289e-05 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9326\n",
            "Epoch 180/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.4183e-05 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9326\n",
            "Epoch 181/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.2978e-05 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.9326\n",
            "Epoch 182/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.1916e-05 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9326\n",
            "Epoch 183/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.0903e-05 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9326\n",
            "Epoch 184/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.9806e-05 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9326\n",
            "Epoch 185/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.8834e-05 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9326\n",
            "Epoch 186/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.7937e-05 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9326\n",
            "Epoch 187/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6999e-05 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9326\n",
            "Epoch 188/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6062e-05 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9326\n",
            "Epoch 189/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5255e-05 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9326\n",
            "Epoch 190/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4410e-05 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9326\n",
            "Epoch 191/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3603e-05 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9326\n",
            "Epoch 192/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2806e-05 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9326\n",
            "Epoch 193/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2125e-05 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9326\n",
            "Epoch 194/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1359e-05 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9326\n",
            "Epoch 195/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0687e-05 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9326\n",
            "Epoch 196/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0014e-05 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9326\n",
            "Epoch 197/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9375e-05 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9326\n",
            "Epoch 198/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.8743e-05 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9326\n",
            "Epoch 199/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.8132e-05 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9326\n",
            "Epoch 200/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7531e-05 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9326\n",
            "Epoch 201/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6964e-05 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9326\n",
            "Epoch 202/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6398e-05 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9326\n",
            "Epoch 203/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5866e-05 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9326\n",
            "Epoch 204/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5360e-05 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.9326\n",
            "Epoch 205/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4858e-05 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9326\n",
            "Epoch 206/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4378e-05 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9326\n",
            "Epoch 207/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3937e-05 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9326\n",
            "Epoch 208/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3494e-05 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9326\n",
            "Epoch 209/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3047e-05 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9326\n",
            "Epoch 210/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2617e-05 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9326\n",
            "Epoch 211/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2247e-05 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9326\n",
            "Epoch 212/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1852e-05 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9326\n",
            "Epoch 213/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1455e-05 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9326\n",
            "Epoch 214/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1109e-05 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9326\n",
            "Epoch 215/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0740e-05 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9326\n",
            "Epoch 216/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0396e-05 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9326\n",
            "Epoch 217/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0066e-05 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9326\n",
            "Epoch 218/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.7385e-06 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9326\n",
            "Epoch 219/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.4306e-06 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9326\n",
            "Epoch 220/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.1445e-06 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9326\n",
            "Epoch 221/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.8562e-06 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9326\n",
            "Epoch 222/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.5697e-06 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9326\n",
            "Epoch 223/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.2883e-06 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9326\n",
            "Epoch 224/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.0325e-06 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9326\n",
            "Epoch 225/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.7955e-06 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9326\n",
            "Epoch 226/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.5292e-06 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9326\n",
            "Epoch 227/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.3008e-06 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9326\n",
            "Epoch 228/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.0642e-06 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9326\n",
            "Epoch 229/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.8404e-06 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9326\n",
            "Epoch 230/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.6345e-06 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9326\n",
            "Epoch 231/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.4158e-06 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9303\n",
            "Epoch 232/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.2234e-06 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9303\n",
            "Epoch 233/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.0253e-06 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9303\n",
            "Epoch 234/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.8284e-06 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9303\n",
            "Epoch 235/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.6545e-06 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9303\n",
            "Epoch 236/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.4773e-06 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9303\n",
            "Epoch 237/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.3045e-06 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9303\n",
            "Epoch 238/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.1418e-06 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9281\n",
            "Epoch 239/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.9837e-06 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9303\n",
            "Epoch 240/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.8262e-06 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9303\n",
            "Epoch 241/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.6811e-06 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9303\n",
            "Epoch 242/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.5318e-06 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9303\n",
            "Epoch 243/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.3842e-06 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9303\n",
            "Epoch 244/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.2512e-06 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.9303\n",
            "Epoch 245/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.1196e-06 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9303\n",
            "Epoch 246/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.9902e-06 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9303\n",
            "Epoch 247/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.8687e-06 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9281\n",
            "Epoch 248/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.7518e-06 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9303\n",
            "Epoch 249/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.6400e-06 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9281\n",
            "Epoch 250/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.5243e-06 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9303\n",
            "Epoch 251/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.4173e-06 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9303\n",
            "Epoch 252/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.3143e-06 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.9303\n",
            "Epoch 253/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.2101e-06 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9281\n",
            "Epoch 254/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.1107e-06 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9303\n",
            "Epoch 255/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.0152e-06 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9303\n",
            "Epoch 256/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.9223e-06 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9303\n",
            "Epoch 257/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.8378e-06 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9281\n",
            "Epoch 258/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.7516e-06 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9303\n",
            "Epoch 259/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6628e-06 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.9281\n",
            "Epoch 260/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5805e-06 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9303\n",
            "Epoch 261/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5026e-06 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9281\n",
            "Epoch 262/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4319e-06 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9281\n",
            "Epoch 263/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3581e-06 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9281\n",
            "Epoch 264/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2864e-06 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9303\n",
            "Epoch 265/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2136e-06 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9281\n",
            "Epoch 266/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1479e-06 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9281\n",
            "Epoch 267/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0809e-06 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9303\n",
            "Epoch 268/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0223e-06 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9281\n",
            "Epoch 269/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9569e-06 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9281\n",
            "Epoch 270/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9027e-06 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9281\n",
            "Epoch 271/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.8419e-06 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9281\n",
            "Epoch 272/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7865e-06 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9281\n",
            "Epoch 273/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7311e-06 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9281\n",
            "Epoch 274/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6827e-06 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9281\n",
            "Epoch 275/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6319e-06 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9281\n",
            "Epoch 276/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5831e-06 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9303\n",
            "Epoch 277/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5379e-06 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9281\n",
            "Epoch 278/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4902e-06 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9281\n",
            "Epoch 279/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4466e-06 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9281\n",
            "Epoch 280/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4019e-06 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9281\n",
            "Epoch 281/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3614e-06 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9281\n",
            "Epoch 282/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3221e-06 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9281\n",
            "Epoch 283/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2815e-06 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9281\n",
            "Epoch 284/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2430e-06 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9281\n",
            "Epoch 285/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2117e-06 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9281\n",
            "Epoch 286/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1722e-06 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9281\n",
            "Epoch 287/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1367e-06 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9281\n",
            "Epoch 288/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1030e-06 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9281\n",
            "Epoch 289/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0714e-06 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9281\n",
            "Epoch 290/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0405e-06 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9281\n",
            "Epoch 291/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0126e-06 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9281\n",
            "Epoch 292/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 9.8033e-07 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9281\n",
            "Epoch 293/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.5180e-07 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9281\n",
            "Epoch 294/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.2447e-07 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9281\n",
            "Epoch 295/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.9614e-07 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9281\n",
            "Epoch 296/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.7344e-07 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9281\n",
            "Epoch 297/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.4618e-07 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9281\n",
            "Epoch 298/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.2147e-07 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9281\n",
            "Epoch 299/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.9937e-07 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9281\n",
            "Epoch 300/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.7406e-07 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9281\n"
          ]
        }
      ]
    }
  ]
}